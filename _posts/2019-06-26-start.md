---
title:  "Machine Learning Starter Kit"
date:   2019-06-26 01:06:09 -0500
layout: post
permalink: /start
image:
  path: "http://zna.do/favicon-32x32.png"
---

A lot of people ask me how to get started with machine learning/artificial intelligence, so took what I usually say and wrote it down in one place!

<style>
#site-title {
  color: #fafafa;
}
#hero-image {
  background-image: url("/assets/start/images/thesis_zacknet.png");
}
.section-title {
  font-size: 16px;
}
</style>

<link rel="stylesheet" href="/assets/css/input.css">

<p>Many people have spent many hours writing down and illustrating how to get started with machine learning, so this will mostly be links to them. Also both the community and this post often use ML/AI (<a href="https://xkcd.com/2048/" target="_blank">machine learning</a>/artificial intelligence) interchangeably. Deep learning (DL) is ML at scale, typically referring to <a href="https://xkcd.com/1838/" target="_blank">neural networks</a>.</p>


<b class="section-title">Getting started</b>
<p>Most ML material nowadays is in Python (even if it calls out to C++ or other more performant code) so being comfortable with Python code is a must.</p>

<p>All of the algorithms and ideas used today in ML are built using linear algebra, calculus, differential equations, and/or probability/statistics. There are a lot of great materials online for these including but not limited to:</p>
<ul>
<li><a href="http://tutorial.math.lamar.edu/" target="_blank">Paul's Online Notes</a></li>
<li>entire university courses like those on <a href="https://ocw.mit.edu/courses/find-by-topic/" target="_blank">MIT Open CourseWare</a></li>
<li>YouTube channels, I particularly love <a href="https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw" target="_blank">3Blue1Brown</a> because of their great use of visualizations to explain concepts (one example being their <a href="https://www.youtube.com/watch?v=Ip3X9LOh2dk" target="_blank">matrix determinant video</a>)</li>
</ul>

<p>One excellent resource to get started with machine learning is the <b>Google ML crash course</b>: <a href="https://developers.google.com/machine-learning/crash-course" target="_blank">developers.google.com/machine-learning/crash-course</a>. This is a comprehensive introduction to many basic machine learning concepts you should be familiar with, in addition to more modern deep learning techniques like neural networks.</p>
<p>There's also <a href="http://neuralnetworksanddeeplearning.com" target="_blank">neuralnetworksanddeeplearning.com</a> which nicely builds up how neural networks work. It also includes some useful tricks people use to get neural nets to work well.</p>


<b class="section-title">Going further</b>
<p>Researchers are more frequently running into the issue of cramming their interactive results into a static text PDF format. Some got together and made <a href="https://distill.pub/" target="_blank">distill.pub</a>, which is a beautiful site with interactive posts that explain technical details of machine learning.</p>

<p>As I mentioned before, more and more university classes are putting their content online for free. This includes some advanced machine learning classes, such as those at Stanford:</p>
<ul>
<li><a href="http://web.stanford.edu/class/cs246/" target="_blank">CS246: Mining Massive Data Sets</a></li>
<li><a href="http://cs231n.github.io/" target="_blank">CS231n Convolutional Neural Networks for Visual Recognition</a></li>
<li><a href="http://web.stanford.edu/class/cs224n/" target="_blank">CS224n: Natural Language Processing with Deep Learning</a></li>
<li><a href="http://web.stanford.edu/class/cs221/" target="_blank">CS221: Artificial Intelligence: Principles and Techniques</a></li>
</ul>
<p>These sites have course outlines, lecture slides, videos, homework assignments, and suggested readings which you may find useful.</p>

<p>Additionally, there is also the "Deep Learning" book available for free at <a href="https://www.deeplearningbook.org" target="_blank">deeplearningbook.org</a>. This covers a comprehensive list of important topics and dives into the mathematical and theoretical background behind deep learning.</p>


<b class="section-title">Social media</b>
<p>Something that has had a noticeably positive effect on my ML career has been making a professional ML Twitter account. The ML community is quite active on Twitter, and they often post papers/projects/ideas that they are working on or find interesting. It's a great format for getting a pulse of the field, although I do have some words of caution: it is quite easy to get FOMO or feel overwhelmed because the field moves so fast, but you just have to remember that people only post when their work is ready for the public eye. You don't see the other 99.9% of the effort that went into making the finished product, and rarely do people publish negative results (although I believe this should be fixed!) As a shameless plug <b><a href="https://twitter.com/zacharynado" target="_blank">here is my ML Twitter account</a></b>, I recommend going through the people I follow and following those whose feeds you find interesting.</p>


<b class="section-title">Reading papers</b>
<p>Other powerful resources you'll soon come across are pre-print servers, namely arXiv (pronounced archive) and OpenReview (<a href="https://openreview.net/group?id=ICLR.cc/2019/Conference" target="_blank">OpenReview for the ICLR 2019 conference</a>.) These are websites where anyone can upload a PDF to share with the community. Often times you'll see papers that are published in conferences here, and many that are not; keep in mind that while most of the time people upload with care, the results in papers that have not been published in conferences may not have been peer reviewed to the same degree as others.</p>

<p>When reading machine learning papers, they often follow a common format. There are no rules around this and definitely not all papers adhere to this format, but many do:</p>
<ol>
<li><b>Introduction</b>: a general framing of the problem/methods discussed in the paper. Usually outlines the importance of the work by giving real world examples of problems it solves. Often times explicitly lists the contributions of the paper.</li>
<li><b>Background/Related Works</b>: an overview of related previous work done in the area of the paper. Very useful if you are looking to get into a subfield and need more information to read! An example of an extremely in depth (and longer than average) related work section is Section 3 of <a href="https://arxiv.org/abs/1811.03600" target="_blank">Measuring the Effects of Data Parallelism on Neural Network Training</a></li>
<li><b>Methods</b>: details about the contributions of the work, sometimes split into multiple sections.</li>
<li><b>Experiments/Results</b>: details about the results of the paper, sometimes split into multiple sections. Often this is where the important result figures in a paper are.</li>
<li><b>Discussion</b>: a recap of the significance of the methods and results of the work. Sometimes authors will list what they believe are promising directions of future work, so if you are looking for ideas to work on (or looking for how to think of ideas to work on) this can be useful.</li>
<li><b>Appendix</b>: extra information/figures that didn't fit into the previous sections within a reasonable (sometimes conference enforced) page limit. If you are looking to reproduce a paper this is often the place the authors include the fine details of their experiment setups. An excellent example of appendices is <a href="https://arxiv.org/abs/1809.11096" target="_blank">the BigGAN paper</a>; I especially like their negative results appendix where they discuss the things they tried that did not work. Including these negative experiments is immensely useful for researchers looking to replicate and expand on your work!</li>
</ol>
<p>Another example where you can see all these sections is in <a href="https://arxiv.org/abs/1906.02530" target="_blank">our recent paper on uncertainty calibration in deep learning</a>; take a look at the PDF and you'll see all the pieces mentioned!</p>


<b class="section-title">Trying ML yourself</b>
<p>One pain-free way to start programming with ML is to use <a href="https://colab.research.google.com" target="_blank">Google Colab</a>, which is a Python notebook where the code runs on Google Cloud so you don't have to install packages/drivers yourself. <b>You can even get a free GPU or TPU with Colab!</b> TPUs are Google's new hardware built specifically for speeding up machine learning. You can run on a GPU by selecting a GPU runtime by going to "Runtime" > "Change runtime type", and <a href="https://cloud.google.com/tpu/docs/colabs" target="_blank">here are some Colab TPU examples</a>.</p>


<b class="section-title">Interesting applications</b>
<p>If the previous info didn't pique your interest then check out some of these recent applications of ML I think are interesting:</p>

<ul>
<li><b><a href="https://openai.com/blog/how-to-train-your-openai-five/" target="_blank">OpenAI Five</a></b>: OpenAI trained an AI to play Dota 2 at a professional level (in general the <a href="https://openai.com/blog/" target="_blank">OpenAI blog</a> has some great posts!)</li>
<li><b><a href="https://magenta.tensorflow.org/" target="_blank">Project Magenta</a></b>: a Google Research group working on AI for creative applications such as writing music and art.</li>
<li><b><a href="https://colab.research.google.com/drive/1rqDwIddy0eunhhV8yrznG4SNiB5XWFJJ" target="_blank">BigGAN interactive Colab</a></b>: a Google Colab where you can play with a copy of one of the currently state of the art image generation models to make realistic and/or trippy pictures.</li>
<li><b><a href="https://openai.com/blog/better-language-models/" target="_blank">GPT-2</a></b>: a language model trained by OpenAI that generates impressively realistic stories (albeit ungrounded from reality.) They are so realistic that they chose not to immediately release the pre-trained model due to concerns of abuse.</li>
<li><b><a href="https://www.youtube.com/watch?v=YQAupr7JxNY" target="_blank">TimbreTron</a></b>: a model that given an audio clip can generate the same clip with a different timbre, as if played by another instrument.</li>
</ul>

<b class="section-title">Parting advice</b>
<ul>
<li>If/when you come up with ideas you want to try, search for related projects first. There are a lot of people in the field and it's growing every day, so it is not unlikely that someone already explored things you are thinking about. If they have, don't be upset; it happens all the time and if anything is validation that your idea is a good one! Plus there are always plenty more ideas to try.</li>
<li>The ML/AI field moves very fast and can be hard to keep up with, so I recommend first exploring the different subjects of ML and then trying to focus on only a few. Many areas are quite interesting though and it can be hard to narrow down your scope, so I have found that sometimes it is easier to select subfields that you are not interested in and temporarily ignore them, then catch up only when you need to, and focus on the remaining areas.</li>
<li>Keep a list somewhere (digital or physical) and write down any idea that comes to you, no matter how silly it seems at the time.</li>
</ul>
<p>I hope this helps you get started on your ML path, feel free to reach out on <a href="https://twitter.com/zacharynado" target="_blank">Twitter</a> with any questions!</p>
